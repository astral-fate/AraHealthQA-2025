import os
import re
import pandas as pd
import openai # Changed from groq
import time
from getpass import getpass
from sklearn.metrics import accuracy_score

# --- NVIDIA API Configuration (MODIFIED) ---
# Your NVIDIA API key will be accessed securely.
try:
    from google.colab import userdata
    NVIDIA_API_KEY = userdata.get('NVIDIA_API_KEY')
    print("Successfully retrieved NVIDIA_API_KEY from Colab secrets.")
except (ImportError, KeyError):
    print("Could not find 'NVIDIA_API_KEY' in Colab secrets.")
    print("Please enter your NVIDIA API key manually.")
    NVIDIA_API_KEY = getpass('NVIDIA API Key: ')

# Initialize the OpenAI client to point to NVIDIA's API endpoint
client = openai.OpenAI(
  base_url = "https://integrate.api.nvidia.com/v1",
  api_key = NVIDIA_API_KEY
)

# --- File paths and column names for the MCQ task ---
INPUT_CSV = '/content/drive/MyDrive/AraHealthQA/t2t1/data/fill-in-the-blank-choices.csv'
OUTPUT_CSV = '/content/drive/MyDrive/AraHealthQA/t2t1/final_result/predictions_fitb_choices_Mixtral.csv' # Changed output file name

# --- Column names ---
QUESTION_COLUMN = 'Question - Arabic'
ANSWER_COLUMN = 'Answer - Arabic'


# --- Chain of Thought & Few-Shot Prompting Configuration ---
# This part remains the same as Mixtral is also a strong instruction-following model
SYSTEM_PROMPT = """You are an expert medical professional and a meticulous exam assistant. Your task is to solve a multiple-choice question in Arabic.
First, you will engage in a step-by-step thinking process in a <thinking> block. Analyze the medical question, evaluate each option (ุฃ, ุจ, ุฌ, ุฏ, ู), and explain your reasoning for choosing the correct answer.
Second, after your reasoning, you MUST provide the final answer on a new line in the format:
Final Answer: [The single Arabic letter of the correct option]

This two-step process is mandatory. Your entire response must be in Arabic.
"""

FEW_SHOT_EXAMPLES = [
    {
        "role": "user",
        "content": """ุงููุฃ ุงููุฑุงุบุงุช ูู ุงูุฌููุฉ ุงูุชุงููุฉ:
ูู ุญุงูุฉ ุงูุงูุตุจุงุจ ุงูุฌูุจูุ ูุดูุฑ ุงูุฎูุงุถ ุฃู ุบูุงุจ ุงูุฑุฌูุงู ุงูููุณู ุนูู ุงูุฌุงูุจ ุงููุตุงุจ ุฅูู ____ุ ูุงูุฐู ููุชุฌ ุนู ____.
ุฃ. ุชุฑุงูู ุงูุณูุงุฆูุ ุนุฒู ุงูุตูุช
ุจ. ุงุญุชุจุงุณ ุงูููุงุกุ ุงูููุงุฑ ุงูุญููุตูุงุช ุงูููุงุฆูุฉ
ุฌ. ุงูุชูููุ ุงูุฎูุงุถ ูุฑููุฉ ุงูุฑุฆุฉ
ุฏ. ููู ุงููุฑูุ ุงูุณุฏุงุฏ ุงูุดุนุจ ุงูููุงุฆูุฉ"""
    },
    {
        "role": "assistant",
        "content": """<thinking>
        1.  **ุชุญููู ุงูุณุคุงู**: ูุณุฃู ุงูุณุคุงู ุนู ุฏูุงูุฉ ุงูุฎูุงุถ ุฃู ุบูุงุจ "ุงูุฑุฌูุงู ุงูููุณู" (tactile fremitus) ูู ุญุงูุฉ "ุงูุงูุตุจุงุจ ุงูุฌูุจู" (pleural effusion) ูุนู ุงูุขููุฉ ุงููุณุจุจุฉ ูุฐูู. ุงูุฑุฌูุงู ุงูููุณู ูู ุงูุงูุชุฒุงุฒ ุงูุฐู ูููู ุงูุดุนูุฑ ุจู ุนูู ุฌุฏุงุฑ ุงูุตุฏุฑ ุฃุซูุงุก ุงูููุงู.
        2.  **ุชูููู ุงูุฎูุงุฑุงุช**:
            * **ุฃ. ุชุฑุงูู ุงูุณูุงุฆูุ ุนุฒู ุงูุตูุช**: ุงูุงูุตุจุงุจ ุงูุฌูุจู ูู ุจุงููุนู ุชุฑุงูู ููุณูุงุฆู ูู ุงูุบุดุงุก ุงูุฌูุจู. ูุฐุง ุงูุณุงุฆู ูุนูู ูุนุงุฒูุ ููุง ูููุน ุงูุชูุงู ุงูุชุฒุงุฒุงุช ุงูุตูุช ูู ุงูุฑุฆุฉ ุฅูู ุฌุฏุงุฑ ุงูุตุฏุฑ. ูุฐุง ูุชุทุงุจู ุชูุงููุง ูุน ะฝะฐัะพะดุฉ ุงูุฎูุงุถ ุงูุฑุฌูุงู ุงูููุณู.
            * **ุจ. ุงุญุชุจุงุณ ุงูููุงุกุ ุงูููุงุฑ ุงูุญููุตูุงุช ุงูููุงุฆูุฉ**: ูุฐุง ูุตู ุญุงูุฉ ุงุณุชุฑูุงุญ ุงูุตุฏุฑ (pneumothorax) ุฃู ุงูุฎูุงุต ุงูุฑุฆุฉ (atelectasis)ุ ูุงูุชู ููุง ููุฌูุฏุงุช ููุฒูุงุฆูุฉ ูุฎุชููุฉ.
            * **ุฌ. ุงูุชูููุ ุงูุฎูุงุถ ูุฑููุฉ ุงูุฑุฆุฉ**: ุงูุชููู ุงูุฑุฆูู (Pulmonary fibrosis) ูุฒูุฏ ูู ูุซุงูุฉ ุฃูุณุฌุฉ ุงูุฑุฆุฉุ ููุง ูุฏ ูุคุฏู ุฅูู ุฒูุงุฏุฉ ุงูุฑุฌูุงู ุงูููุณูุ ูููุณ ุงูุฎูุงุถู.
            * **ุฏ. ููู ุงููุฑูุ ุงูุณุฏุงุฏ ุงูุดุนุจ ุงูููุงุฆูุฉ**: ูุฏ ูุณุจุจ ุงููุฑู ุงูุตุจุงุจูุง ุฌูุจููุงุ ููู ุงูุณุจุจ ุงููุจุงุดุฑ ูุงูุฎูุงุถ ุงูุฑุฌูุงู ูู ูุฐู ุงูุญุงูุฉ ูู ุงูุณุงุฆู ููุณู ุงูุฐู ูุนุฒู ุงูุตูุช. ุงูุฎูุงุฑ "ุฃ" ูุตู ุงูุขููุฉ ุงูููุฒูุงุฆูุฉ ุงููุจุงุดุฑุฉ ุจุดูู ุฃูุถู.
        3.  **ุงูุงุณุชูุชุงุฌ**: ุงูุฎูุงุฑ ุงูุฃูุซุฑ ุฏูุฉ ูู ุฃู ุชุฑุงูู ุงูุณูุงุฆู ูู ูุง ูุณุจุจ ุนุฒู ุงูุตูุชุ ููุง ูุคุฏู ุฅูู ุงูุฎูุงุถ ุงูุฑุฌูุงู ุงูููุณู.
        </thinking>
        Final Answer: ุฃ"""
    },
    {
        "role": "user",
        "content": """ุงููุฃ ุงููุฑุงุบ ูู ุงูุฌููุฉ ุงูุชุงููุฉ:
        ุงูุญูุฑุฉ ูู ุนุฏูู ุฌูุฏูุฉ ุชุณุจุจูุง _______ุ ููู ุชุตูุจ ุนุงุฏุฉู _____ ุงููุฌู.
        ุฃ. ุงููููุฑุงุช ุงูุนูููุฏูุฉ ุงูุฐูุจูุฉุ ุงูุจุดุฑุฉ
        ุจ. ุงูุนูุฏูุงุช B ู Cุ ุงูุฃุฏูุฉ ุงูุดุจููุฉ
        ุฌ. ุงูุนูุฏูุงุช A ู Gุ ุงูุฃุฏูุฉ ุงูุญููููุฉ
        ุฏ. ุงูุนุตูุงุช ุณูุจูุฉ ุงูุฌุฑุงูุ ุงูุฃูุณุฌุฉ ุชุญุช ุงูุฌูุฏ"""
    },
    {
        "role": "assistant",
        "content": """<thinking>
        1.  **ุชุญููู ุงูุณุคุงู**: ูุณุฃู ุงูุณุคุงู ุนู ุงูุนุงูู ุงููุณุจุจ ููุฑุถ "ุงูุญูุฑุฉ" (Erysipelas) ูุงููููุน ุงูุชุดุฑูุญู ุงูุฐู ูุตูุจู ุนุงุฏุฉ ูู ุงููุฌู.
        2.  **ุชูููู ุงูุฎูุงุฑุงุช**:
            * **ุฃ. ุงููููุฑุงุช ุงูุนูููุฏูุฉ ุงูุฐูุจูุฉุ ุงูุจุดุฑุฉ**: ุงููููุฑุงุช ุงูุนูููุฏูุฉ ุชุณุจุจ ุงูุชูุงุจุงุช ุฌูุฏูุฉ ุฃุฎุฑู ูุซู ุงูููุจุงุก ุฃู ุงูุฎุฑุงุฌุงุชุ ูุงูุญูุฑุฉ ุชุตูุจ ุทุจูุฉ ุฃุนูู ูู ุงูุจุดุฑุฉ.
            * **ุจ. ุงูุนูุฏูุงุช B ู Cุ ุงูุฃุฏูุฉ ุงูุดุจููุฉ**: ุงูุนูุฏูุงุช ูู ุงููุฌููุนุฉ B ู C ููุณุช ุงููุณุจุจ ุงูุฃูุซุฑ ุดููุนูุง ููุญูุฑุฉ. ููุง ุฃู ุงูุญูุฑุฉ ุชุตูุจ ุงูุทุจูุฉ ุงูุนููุง ูู ุงูุฃุฏูุฉ.
            * **ุฌ. ุงูุนูุฏูุงุช A ู Gุ ุงูุฃุฏูุฉ ุงูุญููููุฉ**: ุงููุณุจุจ ุงูููุงุณููู ููุญูุฑุฉ ูู ุงูุนูุฏูุงุช ุงูุญุงูุฉ ููุฏู ูู ุงููุฌููุนุฉ ุฃ (Group A Streptococcus). ุชุตูุจ ุงูุนุฏูู ุจุดูู ูููุฒ ุงูุฃุฏูุฉ ุงูุณุทุญูุฉ (ุงูุฃุฏูุฉ ุงูุญููููุฉ) ูุงูุฃูุนูุฉ ุงููููุงููุฉ ุงูุณุทุญูุฉ. ูุฐุง ุงูุฎูุงุฑ ูู ุงูุฃูุซุฑ ุฏูุฉ.
            * **ุฏ. ุงูุนุตูุงุช ุณูุจูุฉ ุงูุฌุฑุงูุ ุงูุฃูุณุฌุฉ ุชุญุช ุงูุฌูุฏ**: ูุฐุง ูุตู ููุนูุง ูุฎุชูููุง ุชูุงููุง ูู ุงูุนุฏูู (ูุซู ุงูุชูุงุจ ุงูููู - cellulitis) ูู ุทุจูุฉ ุฃุนูู ูุจูุชูุฑูุง ูุฎุชููุฉ.
        3.  **ุงูุงุณุชูุชุงุฌ**: ุงูุญูุฑุฉ ุชุณุจุจูุง ุจุดูู ุฃุณุงุณู ุงูุนูุฏูุงุช ูู ุงููุฌููุนุฉ A ูุชุตูุจ ุงูุฃุฏูุฉ ุงูุญููููุฉ (ุงูุณุทุญูุฉ).
        </thinking>
        Final Answer: ุฌ"""
    }
]


# --- Function to Generate Answers for MCQ Task (MODIFIED) ---
def generate_answer(question):
    """
    Sends an MCQ question to the NVIDIA API, prompting the Mixtral model to use
    Chain of Thought. It handles the streaming response and parses the final answer.
    """
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT}
    ]
    messages.extend(FEW_SHOT_EXAMPLES)
    messages.append({"role": "user", "content": question})

    max_retries = 3
    retry_delay = 10 # Increased delay for potentially stricter rate limits
    for attempt in range(max_retries):
        try:
            # API call is now to the new client with streaming enabled
            completion = client.chat.completions.create(
                model="mistralai/mixtral-8x22b-instruct-v0.1",
                messages=messages,
                temperature=0.5,
                top_p=1,
                max_tokens=1024,
                stream=True
            )

            # Handle the streaming response
            response_text = ""
            for chunk in completion:
                if chunk.choices[0].delta.content is not None:
                    response_text += chunk.choices[0].delta.content
            
            response_text = response_text.strip()
            # Parse the fully assembled response
            match = re.search(r"Final Answer:\s*([\u0621-\u064A])", response_text, re.IGNORECASE)

            if match:
                return match.group(1)
            else:
                print(f"  -> Warning: Could not parse final answer from response: '{response_text}'. Recording as empty.")
                return ""

        except Exception as e:
            if attempt < max_retries - 1:
                print(f"  -> An error occurred: {e}. Retrying in {retry_delay} seconds...")
                time.sleep(retry_delay)
            else:
                print(f"  -> API Error after multiple retries: {e}")
                return "API_ERROR"
    return "FAILED_ATTEMPTS"


# --- Function to Evaluate MCQ Accuracy (Unchanged) ---
def evaluate_mcq_accuracy(predictions, ground_truths):
    print("\n" + "="*50)
    print("๐ Starting Evaluation...")
    print("="*50)

    if len(predictions) != len(ground_truths):
        print("Warning: Prediction and ground truth lists have different lengths.")
        min_len = min(len(predictions), len(ground_truths))
        predictions = predictions[:min_len]
        ground_truths = ground_truths[:min_len]

    valid_indices = [i for i, p in enumerate(predictions) if p not in ["API_ERROR", "FAILED_ATTEMPTS", ""]]
    valid_predictions = [predictions[i] for i in valid_indices]
    valid_ground_truths = [ground_truths[i] for i in valid_indices]

    if not valid_predictions:
        print("No valid predictions to evaluate. Check for widespread API or parsing errors.")
        return

    accuracy = accuracy_score(valid_ground_truths, valid_predictions)
    correct_predictions = sum(p == g for p, g in zip(valid_predictions, valid_ground_truths))
    total_valid_predictions = len(valid_predictions)
    total_questions = len(ground_truths)
    failed_or_empty = total_questions - total_valid_predictions

    print(f"Total Questions Attempted: {total_questions}")
    print(f"API/Parsing Errors or Failed Attempts: {failed_or_empty}")
    print(f"Valid Predictions to Evaluate: {total_valid_predictions}")
    print("-" * 20)
    print(f"Correct Predictions: {correct_predictions} / {total_valid_predictions}")
    print(f"๐ Accuracy (on valid responses): {accuracy * 100:.2f}%")
    print("="*50 + "\nโ Evaluation Complete.\n" + "="*50)


# --- Main Execution for MCQ Task (Unchanged) ---
def main():
    try:
        df = pd.read_csv(INPUT_CSV, encoding='utf-8')
    except FileNotFoundError:
        print(f"Error: The file '{INPUT_CSV}' was not found. Please check the path.")
        return
    except Exception as e:
        print(f"An error occurred while reading the CSV: {e}")
        return

    if QUESTION_COLUMN not in df.columns or ANSWER_COLUMN not in df.columns:
        print(f"Error: Required columns ('{QUESTION_COLUMN}', '{ANSWER_COLUMN}') not found in CSV.")
        print(f"Available columns are: {df.columns.tolist()}")
        return

    df.dropna(subset=[QUESTION_COLUMN, ANSWER_COLUMN], inplace=True)
    df.reset_index(drop=True, inplace=True)

    if os.path.exists(OUTPUT_CSV):
        print(f"โ Found existing prediction file: '{OUTPUT_CSV}'.")
        print("Skipping generation and loading predictions for evaluation.")
        predictions_df = pd.read_csv(OUTPUT_CSV, header=None, encoding='utf-8', na_filter=False)
        predictions = predictions_df[0].astype(str).tolist()
    else:
        print(f"'{OUTPUT_CSV}' not found. Starting prediction generation process with Mixtral-8x22B...")
        predictions = []
        total_questions = len(df)
        
        start_time = time.time()

        for index, row in df.iterrows():
            question = row[QUESTION_COLUMN]
            print(f"Processing question {index + 1}/{total_questions}...")
            answer_letter = generate_answer(question)
            predictions.append(answer_letter)
            
            try:
                ground_truth_letter = str(row[ANSWER_COLUMN]).strip()[0]
            except IndexError:
                ground_truth_letter = "N/A"
            
            print(f"  -> Ground Truth: {ground_truth_letter} | Model's Predicted Letter: {answer_letter}")

        end_time = time.time()

        total_duration = end_time - start_time
        minutes = int(total_duration // 60)
        seconds = int(total_duration % 60)
        print("\n" + "="*50)
        print(f"โ Prediction generation complete.")
        print(f"โฑ๏ธ  Total time taken: {minutes} minutes and {seconds} seconds.")
        print("="*50)

        predictions_df = pd.DataFrame(predictions)
        predictions_df.to_csv(OUTPUT_CSV, header=False, index=False, encoding='utf-8')
        print(f"\nSuccessfully saved predictions to '{OUTPUT_CSV}'.")
        try:
            from google.colab import files
            files.download(OUTPUT_CSV)
        except (ImportError, NameError):
            print(f"To download '{OUTPUT_CSV}', please use the file browser in your environment.")

    ground_truths = []
    for ans in df[ANSWER_COLUMN].tolist():
        try:
            ground_truths.append(str(ans).strip()[0])
        except IndexError:
            ground_truths.append("INVALID_TRUTH")

    evaluate_mcq_accuracy(predictions, ground_truths)


if __name__ == "__main__":
    main()
