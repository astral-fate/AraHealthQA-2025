# summary
<details>

  llama-3.3-nemotron-super-49b-v1.5

teuken-7b-instruct-commercial-v0.4

sarvam-m

phi-4-mini-flash-reasoning

kimi-k2-instruct

magistral-small-2506

riva-translate-4b-instruct

mistral-nemotron

deepseek-r1-0528

bielik-11b-v2.3-instruct

marin-8b-instruct

granite-3.3-8b-instruct

qwen3-235b-a22b

eurollm-9b-instruct

gemma-2-9b-cpt-sahabatai-instruct

llama-3.1-nemotron-ultra-253b-v1

qwq-32b

deepseek-r1-distill-llama-8b

gemma-3-1b-it

deepseek-r1-distill-qwen-32b

deepseek-r1-distill-qwen-14b

deepseek-r1-distill-qwen-7b

mistral-small-24b-instruct

deepseek-r1

colosseum_355b_instruct_16k

falcon3-7b-instruct

italia_10b_instruct_16k

qwen2.5-7b-instruct

qwen2.5-coder-32b-instruct

qwen2.5-coder-7b-instruct

palmyra-creative-122b

nemotron-4-mini-hindi-4b-instruct

llama-3.1-nemotron-70b-instruct

zamba2-7b-instruct

llama-3.1-swallow-70b-instruct-v0.1

llama-3.1-swallow-8b-instruct-v0.1

mistral-nemo-minitron-8b-8k-instruct

llama-3.2-3b-instruct

llama-3.2-1b-instruct

llama-3.1-nemotron-51b-instruct

qwen2-7b-instruct

dracarys-llama-3.1-70b-instruct

llama-3-taiwan-7b-instruct

llama-3-swallow-70b-instruct-v0.1

jamba-1.5-mini-instruct

jamba-1.5-large-instruct

phi-3.5-moe-instruct

rakutenai-7b-instruct

rakutenai-7b-chat

palmyra-fin-70b-32k

gemma-2-2b-it

chatglm3-6b

mamba-codestral-7b-v0.1

baichuan2-13b-chat

phi-3-medium-128k-instruct

gemma-2-27b-it

gemma-2-9b-it

llama3-chatqa-1.5-70b

llama3-chatqa-1.5-8b

yi-large

palmyra-med-70b-32k

palmyra-med-70b

breeze-7b-instruct

codegemma-1.1-7b

phi-3-small-8k-instruct

phi-3-small-128k-instruct

phi-3-medium-4k-instruct

phi-3-mini-4k-instruct

dbrx-instruct

phi-3-mini-128k-instruct

mixtral-8x22b-instruct-v0.1

llama3-70b-instruct

llama3-8b-instruct

recurrentgemma-2b

codegemma-7b

gemma-2b

gemma-7b

mistral-7b-instruct-v0.2

mixtral-8x7b-instruct-v0.1
</details>

Top Recommendations
These models have features that make them the most likely to succeed for your specific medical and Arabic test case.

palmyra-med-70b / palmyra-med-70b-32k

Why it's the top choice: This is the only model in your list with "med" explicitly in its name. This indicates it has been specifically fine-tuned on medical data. At 70 billion parameters, it is a large and powerful model that likely retains strong multilingual capabilities from its base model, which would include Arabic. This is the most direct fit for your request. The 32k version simply offers a larger context window for longer documents or conversations.

falcon3-7b-instruct

Why it's a strong contender: Falcon models were originally developed by the Technology Innovation Institute (TII) in the United Arab Emirates (UAE). Because of their origin, they often have a stronger foundation and perform better in Arabic than many other Western or Eastern models. While it's smaller (7B parameters), its specialized regional training could make it surprisingly effective.

qwen3-235b-a22b

Why it's a strong contender: This is a massive model from Alibaba (235 billion parameters). The Qwen series is famous for its exceptional multilingual capabilities, including excellent performance in Arabic. While not medically specialized, its sheer size and advanced reasoning may allow it to understand complex medical terminology and provide accurate answers in Arabic simply due to its vast training data.


https://huggingface.co/spaces/TachyHealth/open_medical_llm_leaderboard_by_openlifescienceai

https://huggingface.co/baichuan-inc/Baichuan-M1-14B-Instruct
https://build.nvidia.com/explore/discover
https://console.groq.com/home
